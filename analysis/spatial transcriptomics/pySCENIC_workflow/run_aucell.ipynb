{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6dc320",
   "metadata": {},
   "source": [
    "AUCell Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20447d4",
   "metadata": {},
   "source": [
    "## AUCell Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5091b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "from multiprocessing import cpu_count\n",
    "from pyscenic.aucell import aucell\n",
    "from ctxcore.genesig import GeneSignature\n",
    "\n",
    "# Inputs\n",
    "MIN_GENES  = 1                \n",
    "SEED       = 777\n",
    "MAX_MB_PER_CHUNK = 800        \n",
    "\n",
    "# Helper functions\n",
    "def _prep_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    need = {\"gene\", \"CellType_Core\", \"TF\"}\n",
    "    missing = need - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Regulon df missing columns: {missing}\")\n",
    "    df = df.copy()\n",
    "    df[\"gene\"] = df[\"gene\"].astype(str)\n",
    "    df[\"CellType_Core\"] = df[\"CellType_Core\"].astype(str).str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "    keep_cols = [\"gene\", \"CellType_Core\", \"TF\"] + ([\"Organ\"] if \"Organ\" in df.columns else [])\n",
    "    df = df[keep_cols].dropna(subset=[\"gene\", \"CellType_Core\", \"TF\"])\n",
    "    return df\n",
    "\n",
    "def _group_genes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (\n",
    "        df.groupby([\"Organ\", \"CellType_Core\"])[\"gene\"]\n",
    "          .apply(lambda s: sorted(pd.unique(s)))\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "def _normalize_inplace(adata_sub, sample_key=\"Sample\", threshold=15000, per_sample=4000, random_state=0):\n",
    "\n",
    "    if sample_key not in adata_sub.obs:\n",
    "        raise KeyError(f\"obs['{sample_key}'] not found\")\n",
    "\n",
    "    if adata_sub.n_obs > threshold:\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        keep_ids = []\n",
    "        for sample, df in adata_sub.obs.groupby(sample_key):\n",
    "            ids = df.index.to_numpy()\n",
    "            take = min(len(ids), per_sample)\n",
    "            choose = rng.choice(ids, size=take, replace=False) if take < len(ids) else ids\n",
    "            keep_ids.append(choose)\n",
    "        keep_ids = np.concatenate(keep_ids)\n",
    "        keep_mask = adata_sub.obs_names.isin(keep_ids)\n",
    "        adata_sub = adata_sub[keep_mask].copy()\n",
    "\n",
    "    if sp.issparse(adata_sub.X):\n",
    "        adata_sub.X = adata_sub.X.tocsr().astype(np.float32)\n",
    "    else:\n",
    "        adata_sub.X = adata_sub.X.astype(np.float32)\n",
    "\n",
    "    sc.pp.normalize_total(adata_sub, target_sum=1e4, inplace=True)\n",
    "    sc.pp.log1p(adata_sub)\n",
    "\n",
    "    return adata_sub\n",
    "\n",
    "def _choose_chunk_size(n_cells: int, n_genes: int, max_mb: int = MAX_MB_PER_CHUNK) -> int:\n",
    "    bytes_per_cell = max(1, n_genes) * 4\n",
    "    max_bytes = max_mb * 1024 * 1024\n",
    "    return max(1, min(n_cells, int(max_bytes // bytes_per_cell)))\n",
    "\n",
    "def _aucell_scores(adata_sub, geneset, seed=SEED, auc_max_rank=2000) -> pd.Series:\n",
    "    sig = GeneSignature(\"sig\", list(geneset))\n",
    "    n_cells, n_genes = adata_sub.n_obs, adata_sub.n_vars\n",
    "    chunk_size = _choose_chunk_size(n_cells, n_genes)\n",
    "    parts = []\n",
    "    for i0 in range(0, n_cells, chunk_size):\n",
    "        i1 = min(i0 + chunk_size, n_cells)\n",
    "        X = adata_sub.X[i0:i1]\n",
    "        if sp.issparse(X):\n",
    "            arr = X.toarray().astype(np.float32, copy=False)\n",
    "        else:\n",
    "            arr = np.asarray(X, dtype=np.float32, order=\"C\")\n",
    "        ex = pd.DataFrame(arr, columns=adata_sub.var_names, index=adata_sub.obs_names[i0:i1])\n",
    "        # Pass the fixed aucMaxRank=2000\n",
    "        sc_chunk = aucell(ex, [sig], num_workers=1, seed=seed, auc_threshold= (auc_max_rank/len(adata_sub.var))).iloc[:, 0]\n",
    "        parts.append(sc_chunk)\n",
    "        del X, arr, ex, sc_chunk\n",
    "        gc.collect()\n",
    "    return pd.concat(parts)\n",
    "\n",
    "def _sanitize_filename(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", s)\n",
    "\n",
    "\n",
    "\n",
    "# Master function\n",
    "\n",
    "def run_tf(tf_df: pd.DataFrame, adata, OUT_ROOT, aucMax=1000):\n",
    "    tf_df = _prep_df(tf_df)\n",
    "    combos = _group_genes(tf_df)\n",
    "    tf_name = tf_df[\"TF\"].astype(str).unique()[0]\n",
    "\n",
    "\n",
    "    organ_obs = adata.obs[\"Organ\"].astype(str)\n",
    "    cell_obs  = adata.obs[\"CellType_Core\"].astype(str).str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "\n",
    "    out_dir = os.path.join(OUT_ROOT, \"regulon_AUCELL\", f\"{aucMax}\", f\"{tf_name}\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    i = 0\n",
    "    for _, row in combos.iterrows():\n",
    "        i += 1\n",
    "        organ = row[\"Organ\"]\n",
    "        cell  = row[\"CellType_Core\"]\n",
    "        gene_list = list(row[\"gene\"])\n",
    "        genes = [g for g in gene_list if g in adata.var_names]\n",
    "\n",
    "        print(\n",
    "            f\"[{i}/{len(combos)}] TF = {tf_name} | Organ={organ} | CellType_Core={cell} | \"\n",
    "            f\"present={len(genes)}/{len(gene_list)}\",\n",
    "            flush=True\n",
    "        )\n",
    "        if len(genes) < MIN_GENES:\n",
    "            continue\n",
    "\n",
    "        mask = (organ_obs == organ) & (cell_obs == cell)\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "\n",
    "        n_cells_subset = int(mask.sum())\n",
    "        print(f\"    {tf_name} | {organ} | {cell} --- {n_cells_subset} cells - normalizing\", flush=True)\n",
    "        ad_sub = adata[mask].copy()\n",
    "        ad_sub = _normalize_inplace(ad_sub)\n",
    "\n",
    "        print(f\"    {tf_name} | {organ} | {cell} --- {ad_sub.n_obs} - scoring\", flush=True)\n",
    "        scores = _aucell_scores(ad_sub, genes, auc_max_rank=aucMax)\n",
    "        scores = scores.reindex(ad_sub.obs_names)\n",
    "\n",
    "        out_df = pd.DataFrame({\n",
    "            \"spot\": ad_sub.obs_names.astype(str).values,\n",
    "            \"score\": scores.values,\n",
    "            \"Organ\": organ,\n",
    "            \"CellType_Core\": cell,\n",
    "            \"auc_max_rank\": aucMax,\n",
    "            \"TF\": tf_name\n",
    "        })\n",
    "        fname = f\"{_sanitize_filename(organ)}__{_sanitize_filename(cell)}__{aucMax}.csv\"\n",
    "        out_path = os.path.join(out_dir, fname)\n",
    "        out_df.to_csv(out_path, index=False)\n",
    "        print(f\"    {tf_name} | {organ} | {cell} - saved\", flush=True)\n",
    "\n",
    "        del ad_sub, scores, out_df\n",
    "        gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fec0b5",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "OUT_ROOT   = \"/project/nchevrier/projects/clevenger1/Projects/ArraySeq/General_Analysis/Revision_Analysis/scenic/Celltypes/AUC_bothIrf1Stat1\"\n",
    "Regulon_dir = \"/project/nchevrier/projects/clevenger1/Projects/ArraySeq/General_Analysis/Revision_Analysis/scenic/Celltypes/Analysis/IRF1_Stat1_Regulons\"\n",
    "aucN = 1000\n",
    "\n",
    "adata = sc.read_h5ad(\"/project/nchevrier/projects/clevenger1/Projects/ArraySeq/General_Analysis/CellTypeDEGs/Objects/adata_filtered_Celltypes_OrganCoordinates.h5ad\")\n",
    "\n",
    "Irf1_df   = pd.read_csv(os.path.join(Regulon_dir, \"Irf1_Regulons_OrganxCore.csv\"))\n",
    "Stat1_df  = pd.read_csv(os.path.join(Regulon_dir, \"Stat1_Regulons_OrganxCore.csv\"))\n",
    "Shared_df = pd.read_csv(os.path.join(Regulon_dir, \"Shared_Regulons_OrganxCore.csv\"))\n",
    "\n",
    "run_tf(Stat1_df, adata, aucMax=aucN, OUT_ROOT = OUT_ROOT)\n",
    "run_tf(Irf1_df,  adata, aucMax=aucN, OUT_ROOT = OUT_ROOT)\n",
    "run_tf(Shared_df,  adata, aucMax=aucN, OUT_ROOT = OUT_ROOT)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
